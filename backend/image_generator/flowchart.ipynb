{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T21:14:42.769661Z",
     "iopub.status.busy": "2025-01-30T21:14:42.769223Z",
     "iopub.status.idle": "2025-01-30T21:14:46.795646Z",
     "shell.execute_reply": "2025-01-30T21:14:46.794775Z",
     "shell.execute_reply.started": "2025-01-30T21:14:42.769611Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.12.14)\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.1/464.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.27.0\n",
      "    Uninstalling huggingface-hub-0.27.0:\n",
      "      Successfully uninstalled huggingface-hub-0.27.0\n",
      "Successfully installed huggingface_hub-0.28.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T21:32:14.452943Z",
     "iopub.status.busy": "2025-01-30T21:32:14.452668Z",
     "iopub.status.idle": "2025-01-30T21:32:14.456823Z",
     "shell.execute_reply": "2025-01-30T21:32:14.456076Z",
     "shell.execute_reply.started": "2025-01-30T21:32:14.452921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "abstract = \"\"\"This work delves into the potential of applying\n",
    "Generative AI techniques to the system design phase, aiming\n",
    "to streamline processes and augment human expertise. Gen AI\n",
    "is used to automate the creation of complex design elements and\n",
    "is emerging as a powerful tool for system engineers. Also, with\n",
    "LLM-generated content, evaluating and verifying the correctness\n",
    "of the responses is a challenge. The SE Assistant designed\n",
    "for system engineers intends to create detailed system design\n",
    "documents quickly and accurately along with its evaluation.\n",
    "At the core of the SE Assistant is a sophisticated system that\n",
    "combines the power of GPT-4 with a Multimodal Retrieval\n",
    "Augmented Generation (RAG) pipeline capable of understanding\n",
    "text, images, and tables to provide valuable context. The evaluation uses the strength of strong LLMs in analyzing content\n",
    "based on design-specific criteria. The SE Assistant prototype\n",
    "demonstrates its ability to streamline the system design process,\n",
    "from initial data gathering to the final design output, making it\n",
    "an invaluable tool for system engineers.\n",
    "Index Terms—Generative AI , System Engineering, System Design, Large Language Model, Retrieval Augmented Generation\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T21:44:20.119516Z",
     "iopub.status.busy": "2025-01-30T21:44:20.119161Z",
     "iopub.status.idle": "2025-01-30T21:44:20.125775Z",
     "shell.execute_reply": "2025-01-30T21:44:20.124836Z",
     "shell.execute_reply.started": "2025-01-30T21:44:20.119487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "def create_flowchart_prompt(abstract):\n",
    "    prompt = \"\"\"You are an expert in creating detailed, realistic flowcharts using Mermaid.js syntax.\n",
    "Given the following text, create a comprehensive flowchart that captures all key relationships and processes.\n",
    "\n",
    "Follow these precise guidelines:\n",
    "\n",
    "1. RELATIONSHIP MAPPING:\n",
    "   - Identify all direct and indirect relationships between elements\n",
    "   - Use appropriate connection types:\n",
    "     * -->: For direct sequential flow\n",
    "     * -.->: For indirect/conditional relationships\n",
    "     * ==>: For emphasized/major relationships\n",
    "     * --o: For optional relationships\n",
    "     * --x: For alternative paths\n",
    "\n",
    "2. PROCESS STRUCTURE:\n",
    "   - Use clear node types:\n",
    "     * [Rectangle]: Main processes and actions\n",
    "     * (Rounded Rectangle): Sub-processes\n",
    "     * {Hexagon}: Input/Output points\n",
    "     * <Diamond>: Decision points with multiple outcomes\n",
    "     * ((Circle)): Start/End points\n",
    "\n",
    "3. VISUAL ORGANIZATION:\n",
    "   - Group related processes using subgraph\n",
    "   - Maintain clear hierarchical structure\n",
    "   - Use meaningful node IDs (e.g., 'process_1' instead of 'A')\n",
    "   - Add descriptive labels to all connections\n",
    "\n",
    "4. ADVANCED FEATURES:\n",
    "   - Use click events for interactive nodes when relevant\n",
    "   - Implement proper styling (e.g., colors, line styles)\n",
    "   - Add annotations for complex relationships\n",
    "   - Include tooltips for additional context\n",
    "\n",
    "Example Input: \"Describe the software deployment process.\"\n",
    "\n",
    "Example Output:\n",
    "```mermaid\n",
    "graph TD\n",
    "    subgraph Development\n",
    "        start((Start)) --> code[Write Code]\n",
    "        code --> test{Unit Tests}\n",
    "        test -->|Failed| code\n",
    "        test -->|Passed| review[Code Review]\n",
    "    end\n",
    "    \n",
    "    subgraph Deployment\n",
    "        review -->|Approved| build[Build Package]\n",
    "        build --> staging[Deploy to Staging]\n",
    "        staging --> integration{Integration Tests}\n",
    "        integration -->|Failed| code\n",
    "        integration -->|Passed| prod[Deploy to Production]\n",
    "        prod --> monitor[Monitor Performance]\n",
    "        monitor -.-> rollback[Rollback if Issues]\n",
    "        rollback --> code\n",
    "    end\n",
    "    \n",
    "    classDef critical fill:#ff6b6b\n",
    "    classDef process fill:#4ecdc4\n",
    "    class rollback critical\n",
    "    class start,prod process\n",
    "```\n",
    "\n",
    "Now, create a detailed flowchart for the following text while maintaining all relationships and processes:\n",
    "\"\"\" + abstract\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    client = InferenceClient(api_key=\"your api key\")\n",
    "    \n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "        messages=messages,\n",
    "        temperature=0.3,  # Lower temperature for more consistent output\n",
    "        max_tokens=2048,\n",
    "        top_p=0.9,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    # Collect and process the response\n",
    "    flowchart = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            flowchart += chunk.choices[0].delta.content\n",
    "            print(chunk.choices[0].delta.content, end=\"\")\n",
    "    \n",
    "    return flowchart\n",
    "\n",
    "# Function to validate mermaid syntax\n",
    "def validate_mermaid_syntax(flowchart):\n",
    "    # Basic validation checks\n",
    "    required_elements = ['graph TD', '-->', '[', ']']\n",
    "    for element in required_elements:\n",
    "        if element not in flowchart:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T21:44:36.656099Z",
     "iopub.status.busy": "2025-01-30T21:44:36.655772Z",
     "iopub.status.idle": "2025-01-30T21:44:44.043191Z",
     "shell.execute_reply": "2025-01-30T21:44:44.042376Z",
     "shell.execute_reply.started": "2025-01-30T21:44:36.656072Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here's a detailed flowchart for the given text using Mermaid.js syntax:\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    subgraph Input: Initial Data Gathering\n",
      "        start((Start)) --> data[Gather Data]\n",
      "    end\n",
      "\n",
      "    subgraph Generation: System Design\n",
      "        data --> rag[Multimodal Retrieval Augmented Generation (RAG) Pipeline]\n",
      "        rag --> gpt[GPT-4]\n",
      "        gpt --> design[Generate System Design Documents]\n",
      "    end\n",
      "\n",
      "    subgraph Evaluation\n",
      "        design --> evaluation{Evaluate Design Documents}\n",
      "        evaluation -->|Passed| approve[Approve Design]\n",
      "        evaluation -->|Failed| revise[Revise Design]\n",
      "    end\n",
      "\n",
      "    subgraph Output: Final Design Output\n",
      "        revise --> rag\n",
      "        rag --> gpt\n",
      "        gpt --> design\n",
      "        design --> approve\n",
      "        approve --> output[Final Design Output]\n",
      "    end\n",
      "\n",
      "    subgraph SE Assistant\n",
      "        data --> se_assistant[SE Assistant]\n",
      "        se_assistant --> rag\n",
      "        se_assistant --> evaluation\n",
      "        se_assistant --> output\n",
      "    end\n",
      "\n",
      "    classDef process fill:#4ecdc4\n",
      "    classDef evaluation critical fill:#ff6b6b\n",
      "    class start,output process\n",
      "```\n",
      "\n",
      "This flowchart represents the process of using the SE Assistant to generate system design documents using Generative AI techniques. It includes the initial data gathering, the generation process with GPT-4 and the Multimodal Retrieval Augmented Generation (RAG) pipeline, the evaluation of the design documents, and the final design output. The evaluation process is highlighted as a critical step due to the challenges in evaluating and verifying the correctness of the responses from LLMs.\n",
      "Generated Mermaid.js Flowchart:\n",
      "\n",
      " Here's a detailed flowchart for the given text using Mermaid.js syntax:\n",
      "\n",
      "```mermaid\n",
      "graph TD\n",
      "    subgraph Input: Initial Data Gathering\n",
      "        start((Start)) --> data[Gather Data]\n",
      "    end\n",
      "\n",
      "    subgraph Generation: System Design\n",
      "        data --> rag[Multimodal Retrieval Augmented Generation (RAG) Pipeline]\n",
      "        rag --> gpt[GPT-4]\n",
      "        gpt --> design[Generate System Design Documents]\n",
      "    end\n",
      "\n",
      "    subgraph Evaluation\n",
      "        design --> evaluation{Evaluate Design Documents}\n",
      "        evaluation -->|Passed| approve[Approve Design]\n",
      "        evaluation -->|Failed| revise[Revise Design]\n",
      "    end\n",
      "\n",
      "    subgraph Output: Final Design Output\n",
      "        revise --> rag\n",
      "        rag --> gpt\n",
      "        gpt --> design\n",
      "        design --> approve\n",
      "        approve --> output[Final Design Output]\n",
      "    end\n",
      "\n",
      "    subgraph SE Assistant\n",
      "        data --> se_assistant[SE Assistant]\n",
      "        se_assistant --> rag\n",
      "        se_assistant --> evaluation\n",
      "        se_assistant --> output\n",
      "    end\n",
      "\n",
      "    classDef process fill:#4ecdc4\n",
      "    classDef evaluation critical fill:#ff6b6b\n",
      "    class start,output process\n",
      "```\n",
      "\n",
      "This flowchart represents the process of using the SE Assistant to generate system design documents using Generative AI techniques. It includes the initial data gathering, the generation process with GPT-4 and the Multimodal Retrieval Augmented Generation (RAG) pipeline, the evaluation of the design documents, and the final design output. The evaluation process is highlighted as a critical step due to the challenges in evaluating and verifying the correctness of the responses from LLMs.\n"
     ]
    }
   ],
   "source": [
    "flowchart_output = create_flowchart_prompt(abstract)\n",
    "\n",
    "# Print the Mermaid.js flowchart syntax\n",
    "print(\"\\nGenerated Mermaid.js Flowchart:\\n\")\n",
    "print(flowchart_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T22:04:22.383919Z",
     "iopub.status.busy": "2025-01-30T22:04:22.383633Z",
     "iopub.status.idle": "2025-01-30T22:04:22.390119Z",
     "shell.execute_reply": "2025-01-30T22:04:22.389241Z",
     "shell.execute_reply.started": "2025-01-30T22:04:22.383897Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file created: mermaid_flowchart.html\n",
      "Please open this file in a web browser to view the flowchart.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_mermaid_html_file(mermaid_code, filename=\"mermaid_flowchart.html\"):\n",
    "    \"\"\"\n",
    "    Create a static HTML file with Mermaid.js diagram\n",
    "    \"\"\"\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Mermaid Flowchart</title>\n",
    "        <script src=\"https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js\"></script>\n",
    "        <script>\n",
    "            mermaid.initialize({{ \n",
    "                startOnLoad: true,\n",
    "                theme: 'default'\n",
    "            }});\n",
    "        </script>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"mermaid\">\n",
    "            {mermaid_code}\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"HTML file created: {filename}\")\n",
    "    print(\"Please open this file in a web browser to view the flowchart.\")\n",
    "\n",
    "# Create the HTML file\n",
    "create_mermaid_html_file(mermaid_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
